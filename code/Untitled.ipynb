{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2698c24",
   "metadata": {},
   "source": [
    "## Loading Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c166856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import importlib\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "from mpl_toolkits import mplot3d\n",
    "from io import BytesIO\n",
    "from math import log, exp, tan, atan, ceil\n",
    "from PIL import Image\n",
    "\n",
    "from utils import dataset_utils\n",
    "from utils import createAISdata\n",
    "#from utils import protobufDecoder\n",
    "#from utils import plotting\n",
    "from models import VRNN\n",
    "from Config import config\n",
    "\n",
    "# To measure the training time\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e929de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "if device==\"cuda:0\":\n",
    "    torch.no_grad()\n",
    "    torch.cuda.empty_cache()\n",
    "#timestamp = datetime.datetime.fromtimestamp(update.t_epoch_sec).strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "shiptypes = config.SHIPTYPE_CARGO + config.SHIPTYPE_TANKER\n",
    "shipFileName = 'test'\n",
    "binedges = (config.LAT_EDGES, config.LON_EDGES, config.SOG_EDGES, config.COG_EDGES)\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1819c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//Pickle//CargTank_1911.pkl\"\n",
    "#path_index = \"C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//Pickle//CargTank_1911_idxs.pkl\"\n",
    "\n",
    "path = \"C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//test.pkl\"\n",
    "path_index = \"C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//CargTank_1911_idxs.pkl\"\n",
    "\n",
    "datasets_path = \"C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//\"\n",
    "#datasets_path = \"C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//Pickle//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eeaefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSequence:\n",
    "    def __call__(self, batch):\n",
    "                \n",
    "        # each element in \"batch\" is a tuple ( mmsis,  shiptypes,  lengths, inputs, targets)\n",
    "        # Get each sequence and pad it\n",
    "        mmsis = [x[0] for x in batch] # Maritime Mobile Service Identity numbers\n",
    "        shiptypes = [x[1] for x in batch] # tank, cargo, etc.\n",
    "        lengths = [x[2] for x in batch] # used as measure of size\n",
    "        inputs = [x[3] for x in batch] # they are normalized \n",
    "        targets = [x[4] for x in batch] # seems to contain the real path of the vessel\n",
    "                                        # lat, lon, speed, course (NOT NORMALIZED)\n",
    "                \n",
    "        inputs_padded = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "        targets_padded = torch.nn.utils.rnn.pad_sequence(targets, batch_first=True)\n",
    "\n",
    "        return  torch.tensor(mmsis),  torch.tensor(shiptypes),  torch.tensor(lengths, dtype=torch.float), inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0134face",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataPath: C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//\n",
      "fileName: CargTank_1911.pkl\n",
      "self.params[dataFileName]: CargTank_1911_idxs.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.datapath 12 C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//CargTank_1911_idxs.pkl\n",
      "index:  2777757   total_updates:  238708\n"
     ]
    }
   ],
   "source": [
    "# different lengths (use max/min for dimensions)\n",
    "trainset = dataset_utils.AISDataset(dataPath = datasets_path, fileName = \"CargTank_1911.pkl\", indexFileName = config.index_fileName)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers = 0, collate_fn=PadSequence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e75a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dataPath: C://Users//asm//OneDrive - Netcompany/University//Master Thesis//Data//\n",
      "fileName: CargTank_1911.pkl\n",
      "self.params[dataFileName]: CargTank_1911_idxs.pkl\n"
     ]
    }
   ],
   "source": [
    "testset = dataset_utils.AISDataset(dataPath = datasets_path, fileName = \"CargTank_1911.pkl\", indexFileName = config.index_fileName, train_mean = trainset.mean)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers = 0, collate_fn=PadSequence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "455211f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = len(trainset)\n",
    "test_n = len(testset)\n",
    "num_batches = len(train_loader)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dac505f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size is: 3604 and Test set size is 902 \n"
     ]
    }
   ],
   "source": [
    "print('Training set size is: {} and Test set size is {} '.format(train_n,test_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26fe27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VRNN.VRNN(input_shape=trainset.datadim, latent_shape=config.LATENT_SIZE, generative_bias=trainset.mean, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027079e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.datadim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e048003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLoss(log_px, log_pz, log_qz, lengths, beta=1):\n",
    "    \n",
    "    max_len = len(log_px)\n",
    "    curmask = torch.arange(max_len, device=device)[:, None] < lengths[None, :] #max_seq_len X Batch\n",
    "    \n",
    "    log_px = torch.stack(log_px, dim=0) * curmask\n",
    "    log_px = log_px.sum(dim=0) #Sum over time\n",
    "   \n",
    "    log_pz = torch.stack(log_pz, dim=0) * curmask\n",
    "    log_qz = torch.stack(log_qz, dim=0) * curmask\n",
    "    kl = log_qz.sum(dim=0) - log_pz.sum(dim=0) #Sum over time\n",
    "    \n",
    "    loss = log_px - beta * kl #recon loss - beta_kl\n",
    "    loss = torch.mean(loss/lengths) #mean over batch\n",
    "    \n",
    "    return -loss, log_px, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2b9c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tot = []\n",
    "kl_tot = []\n",
    "recon_tot = []\n",
    "val_loss_tot = []\n",
    "val_kl_tot = []\n",
    "val_recon_tot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a787008",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examining the training set\n",
    "\n",
    "#for i, (_, _, lengths, inputs, targets) in enumerate(train_loader):\n",
    "    #print(lengths)\n",
    "#    print('####################')\n",
    "#    print(inputs.shape)\n",
    "#    print('####################')\n",
    "#    print(targets.shape)\n",
    "    #targets = targets.to(device)\n",
    "    #lengths = lengths.to(device)\n",
    "#    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b53bf0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel():\n",
    "    \n",
    "    ##\n",
    "    for epoch in range(1, num_epochs+1): #num_epochs+1\n",
    "        #Begin training loop\n",
    "        tic = time()\n",
    "\n",
    "        loss_epoch = 0\n",
    "        kl_epoch = 0\n",
    "        recon_epoch = 0\n",
    "        model.train()\n",
    "        for i, (_, _, lengths, inputs, targets) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            log_px, log_pz, log_qz, _, _ = model(inputs,targets,logits=None)\n",
    "\n",
    "            loss, log_px, kl = computeLoss(log_px, log_pz, log_qz, lengths)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_epoch += loss.item()*len(lengths)\n",
    "            kl_epoch += torch.sum(kl/lengths).item()\n",
    "            recon_epoch += torch.sum(log_px/lengths).item()\n",
    "\n",
    "        loss_tot.append(loss_epoch/train_n)\n",
    "        kl_tot.append(kl_epoch/train_n)\n",
    "        recon_tot.append(recon_epoch/train_n)\n",
    "\n",
    "        #Begin validation loop\n",
    "        val_loss = 0\n",
    "        val_kl = 0\n",
    "        val_recon = 0\n",
    "        model.eval()\n",
    "        for i, (_, _, lengths, inputs, targets) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            log_px, log_pz, log_qz, _, _ = model(inputs,targets,logits=None)\n",
    "\n",
    "            loss, log_px, kl = computeLoss(log_px, log_pz, log_qz, lengths)\n",
    "\n",
    "            val_loss += loss.item()*len(lengths)\n",
    "            val_kl += torch.sum(kl/lengths).item()\n",
    "            val_recon += torch.sum(log_px/lengths).item()\n",
    "\n",
    "        val_loss_tot.append(val_loss/test_n)\n",
    "        val_kl_tot.append(val_kl/test_n)\n",
    "        val_recon_tot.append(val_recon/test_n)\n",
    "\n",
    "        datapoints = np.random.choice(test_n, size = 3, replace=False)\n",
    "        #plotting.make_vae_plots((loss_tot, kl_tot, recon_tot, val_loss_tot, val_kl_tot, val_recon_tot), model, datapoints, testset, binedges, device)\n",
    "\n",
    "        #print('Epoch {} of {} finished. Trainingloss = {}. Validationloss = {}'.format(epoch, num_epochs, loss_epoch/train_n, val_loss/test_n))\n",
    "        print('Epoch {} of {} finished. Trainingloss = {}. Validationloss = {}'.format(epoch, num_epochs, loss_epoch/train_n, val_loss/test_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4278a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f620f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd988d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddec43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index:  2777757   total_updates:  238708  totalRows:  238708\n",
    "#index:  9727785   total_updates:  190279  totalRows:  190279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e19cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
